{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.decomposition import PCA\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('bow&dic/bow_train_over15.csv')\n",
    "DF_file = pd.ExcelFile('bow&dic/df_Dic_org_over15_t.xlsx')\n",
    "dfreq = DF_file.parse('Sheet1')\n",
    "data.columns = dfreq.columns\n",
    "data = data.drop(\"['positive'\", axis=1)\n",
    "#data = data.drop(columns=[ '0.1'])# delete positive column\n",
    "#data = data[:100] \n",
    "\"\"\"\n",
    "import seaborn.apionly as sns\n",
    "from sklearn import preprocessing\n",
    "data = sns.load_dataset('iris')\n",
    "le = preprocessing.LabelEncoder()\n",
    "#convert the categorical columns into numeric\n",
    "data['species'] = le.fit_transform(data['species'])\n",
    "\"\"\"\n",
    "\n",
    "row_count = data.shape[0]\n",
    "split_point = int(row_count*4/5)\n",
    "train_data, test_data = data[:split_point], data[split_point:]\n",
    "###########\n",
    "#X_train, X_test, y_train, y_test = train_test_split(data.loc[:,data.columns != 'species'], data['species'], test_size=0.2)\n",
    "###########\n",
    "#train_data = np.c_[ X_train,y_train ]\n",
    "###########\n",
    "#train_data = pd.concat([ X_train,y_train],axis=1)\n",
    "#test_data = pd.concat([ X_test,y_test],axis=1)\n",
    "###########\n",
    "#test_data = np.c_[ X_test,y_test ]\n",
    "\n",
    "def gini(array):\n",
    "    array = np.array(array)\n",
    "    array = array.flatten()\n",
    "    if np.amin(array) < 0:\n",
    "        # Values cannot be negative:\n",
    "        array -= np.amin(array)\n",
    "    # Values cannot be 0:\n",
    "    array = array + 0.0000001\n",
    "    # Values must be sorted:\n",
    "    array = np.sort(array)\n",
    "    # Index per array element:\n",
    "    index = np.arange(1,array.shape[0]+1)\n",
    "    # Number of array elements:\n",
    "    n = array.shape[0]\n",
    "    # Gini coefficient/index/ratio:\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array)))\n",
    "\n",
    "\n",
    "def feature_selection_technique(train, test, technique ,nFeature):\n",
    "    \n",
    "    train_label = train.iloc[:,0]\n",
    "    test_label = test.iloc[:,0]\n",
    "    X = train.iloc[:,1:]\n",
    "    Y = train_label\n",
    "\n",
    "    \"\"\"\n",
    "    train_label = y_train #train['species']\n",
    "    test_label = y_test #test['species']\n",
    "    Y = train_label\n",
    "    X = train.iloc[:,0:-1]\n",
    "    \"\"\"\n",
    "    \n",
    "    if technique == \"Correlation\":\n",
    "        i=1;\n",
    "        corr_indexes = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            this_column = train.iloc[:,i]\n",
    "            temp = pd.concat([ train_label,this_column ],axis=1)\n",
    "            cor = temp.corr(method='pearson')\n",
    "            corr_indexes[i-1] = abs(cor[\"['negative'\"])[1]\n",
    "            i+=1;\n",
    "        relevant_features = corr_indexes.sort_values(ascending=False)\n",
    "        new_train = train[relevant_features[0:nFeature+1].index] \n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "        \n",
    "    elif technique == \"Correlation&DF\":\n",
    "        i=1;\n",
    "        corr_indexes = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            this_column = train.iloc[:,i]\n",
    "            temp = pd.concat([ train_label,this_column ],axis=1)\n",
    "            cor = temp.corr(method='pearson')\n",
    "            corr_indexes[i-1] = abs(cor[\"['negative'\"])[1]\n",
    "            i+=1;\n",
    "        dfrec =  dfreq.loc[0][2:] / dfreq.loc[0][2:].max()\n",
    "        relevant_features = corr_indexes + dfrec\n",
    "        relevant_features = relevant_features.sort_values(ascending=False)\n",
    "        \n",
    "        new_train = train[relevant_features[0:nFeature+1].index] \n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "        \n",
    "    elif technique == \"Odds_Ratio&DF\":\n",
    "        i=1;\n",
    "        odds_ratios = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            this_column = train.iloc[:,i]\n",
    "            table = np.zeros((2, 2))\n",
    "            temp = this_column[train_label==1]\n",
    "            table[0,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            table[1,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==1]\n",
    "            table[0,1] = temp[temp == 0].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            table[1,1] = temp[temp == 0].shape[0]\n",
    "            oddsratio, pvalue = stats.fisher_exact(table)\n",
    "            odds_ratios[i-1] = oddsratio\n",
    "            i+=1;\n",
    "            \n",
    "        dfrec =  dfreq.loc[0][2:] / dfreq.loc[0][2:].max()\n",
    "        relevant_features = odds_ratios + dfrec\n",
    "        relevant_features = relevant_features.sort_values(ascending=False)\n",
    "        \n",
    "        new_train = train[relevant_features[0:nFeature+1].index] \n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "        \n",
    "    elif technique == \"Correlation&DFS\":\n",
    "        i=1;\n",
    "        corr_indexes = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        DFS_weights = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            #correlation\n",
    "            this_column = train.iloc[:,i]\n",
    "            temp0 = pd.concat([ train_label,this_column ],axis=1)\n",
    "            cor = temp0.corr(method='pearson')\n",
    "            corr_indexes[i-1] = abs(cor[\"['negative'\"])[1]\n",
    "            \n",
    "            #DFS\n",
    "            org_table = np.zeros((2, 1))# number of occurrence per each class\n",
    "            temp = this_column[train_label==1]\n",
    "            org_table[0,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            org_table[1,0] = temp[temp == 1].shape[0]\n",
    "            occurrence_of_word = train.iloc[:,i].sum()\n",
    "            numerator = org_table / occurrence_of_word # calculate numerator of DFS\n",
    "            # calculate denominator of DFS\n",
    "            n_negative = train_label.sum() # number of negative samples\n",
    "            n_positive = train_label.shape[0] - n_negative # number of positive samples\n",
    "            s1 = ((n_negative - org_table.item(0)) / n_negative ) + (( org_table.item(1)) / n_positive ) +1\n",
    "            s2 = ((n_positive - org_table.item(1)) / n_positive ) + (( org_table.item(0)) / n_negative ) +1\n",
    "            # calculate DFS\n",
    "            s = np.array([s1, s2])\n",
    "            s = np.transpose(numerator)/s\n",
    "            DFS_weights[i-1] = s.sum()\n",
    "            i+=1;\n",
    "        relevant_features = corr_indexes + DFS_weights\n",
    "        relevant_features = relevant_features.sort_values(ascending=False)\n",
    "        \n",
    "        new_train = train[relevant_features[0:nFeature+1].index] \n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "    \n",
    "    elif technique == \"Odds_Ratio&DFS\":\n",
    "        i=1;\n",
    "        odds_ratios = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        DFS_weights = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            #odds_ratio\n",
    "            this_column = train.iloc[:,i]\n",
    "            table = np.zeros((2, 2))\n",
    "            temp = this_column[train_label==1]\n",
    "            table[0,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            table[1,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==1]\n",
    "            table[0,1] = temp[temp == 0].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            table[1,1] = temp[temp == 0].shape[0]\n",
    "            oddsratio, pvalue = stats.fisher_exact(table)\n",
    "            odds_ratios[i-1] = oddsratio\n",
    "            \n",
    "            #DFS\n",
    "            org_table = np.zeros((2, 1))# number of occurrence per each class\n",
    "            temp = this_column[train_label==1]\n",
    "            org_table[0,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            org_table[1,0] = temp[temp == 1].shape[0]\n",
    "            occurrence_of_word = train.iloc[:,i].sum()\n",
    "            numerator = org_table / occurrence_of_word # calculate numerator of DFS\n",
    "            # calculate denominator of DFS\n",
    "            n_negative = train_label.sum() # number of negative samples\n",
    "            n_positive = train_label.shape[0] - n_negative # number of positive samples\n",
    "            s1 = ((n_negative - org_table.item(0)) / n_negative ) + (( org_table.item(1)) / n_positive ) +1\n",
    "            s2 = ((n_positive - org_table.item(1)) / n_positive ) + (( org_table.item(0)) / n_negative ) +1\n",
    "            # calculate DFS\n",
    "            s = np.array([s1, s2])\n",
    "            s = np.transpose(numerator)/s\n",
    "            DFS_weights[i-1] = s.sum()\n",
    "            i+=1;   \n",
    "        relevant_features = odds_ratios + DFS_weights\n",
    "        relevant_features = relevant_features.sort_values(ascending=False)\n",
    "        \n",
    "        new_train = train[relevant_features[0:nFeature+1].index] \n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "        \n",
    "    elif technique == \"Correlation&Gini\":\n",
    "        i=1;\n",
    "        corr_indexes = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        gini_indexes = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            #correlation\n",
    "            this_column = train.iloc[:,i]\n",
    "            temp0 = pd.concat([ train_label,this_column ],axis=1)\n",
    "            cor = temp0.corr(method='pearson')\n",
    "            corr_indexes[i-1] = abs(cor[\"['negative'\"])[1]\n",
    "            \n",
    "            #Gini\n",
    "            gini_indexes[i-1] = gini(X[col])\n",
    "            i+=1;\n",
    "        relevant_features = corr_indexes + gini_indexes\n",
    "        relevant_features = relevant_features.sort_values(ascending=False)\n",
    "        \n",
    "        new_train = train[relevant_features[0:nFeature+1].index] \n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "        \n",
    "    elif technique == \"Correlation&Information_Gain\":\n",
    "        cor = train.corr(method='pearson')\n",
    "        #Correlation with output label\n",
    "        cor_target = abs(cor[\"['negative'\"])\n",
    "        #Selecting highly correlated features\n",
    "        #relevant_features = cor_target.sort_values(ascending=False)\n",
    "        \n",
    "        #Info_Gain\n",
    "        mutual_inf_target = mutual_info_classif(train, train_label)\n",
    "        \n",
    "        relation_weight = cor_target * mutual_inf_target\n",
    "        relevant_features = relation_weight.sort_values(ascending=False)\n",
    "        \n",
    "        new_train = train[relevant_features[0:nFeature+1].index] #first column is label\n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[1:nFeature+1]\n",
    "        \n",
    "    elif technique == \"Odds_Ratio&Information_Gain\":\n",
    "        i=1;\n",
    "        odds_ratios = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            #Odd ratio\n",
    "            this_column = train.iloc[:,i]\n",
    "            table = np.zeros((2, 2))\n",
    "            temp = this_column[train_label==1]\n",
    "            table[0,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            table[1,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==1]\n",
    "            table[0,1] = temp[temp == 0].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            table[1,1] = temp[temp == 0].shape[0]\n",
    "            oddsratio, pvalue = stats.fisher_exact(table)\n",
    "            odds_ratios[i-1] = oddsratio\n",
    "            i+=1;\n",
    "        #Information gain\n",
    "        mutual_inf_target = mutual_info_classif(X, train_label)\n",
    "        \n",
    "        relevant_features = odds_ratios + mutual_inf_target\n",
    "        relevant_features = relevant_features.sort_values(ascending=False)\n",
    "        \n",
    "        new_train = train[relevant_features[0:nFeature+1].index] \n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "        \n",
    "    elif technique == \"Information_Gain\":\n",
    "        selector = SelectKBest(mutual_info_classif, k=nFeature)\n",
    "        new_train = selector.fit_transform(X,Y)\n",
    "        relevant_features = X.columns[selector.get_support(indices=True)].tolist()\n",
    "        new_test = test[relevant_features]\n",
    "        train_label=np.array(train_label)\n",
    "        test_label=np.array(test_label)\n",
    "        new_train = np.c_[ train_label,new_train ]#first column is label\n",
    "        new_test = np.c_[ test_label,new_test ]#first column is label\n",
    "        \n",
    "    elif technique == \"Gini_Index\":\n",
    "        i=0;\n",
    "        gini_indexes = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            gini_indexes[i] = gini(X[col])\n",
    "            i+=1;\n",
    "        relevant_features = gini_indexes.sort_values(ascending=False)\n",
    "        new_train = train[relevant_features[0:nFeature+1].index] \n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "    \n",
    "    elif technique == \"Document_Frequency\":\n",
    "        relevant_features = dfreq.loc[0][:].sort_values(ascending=False) \n",
    "        #relevant_features = relevant_features / max(relevant_features)\n",
    "        new_train = train[relevant_features[2:nFeature+3].index] #first & second are NEGATIVE & POSITIVE\n",
    "        new_test = test[relevant_features[2: nFeature+3].index]\n",
    "        relevant_features = relevant_features[2:nFeature+3]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "        \n",
    "    elif technique == \"Odds_Ratio\":\n",
    "        i=1;\n",
    "        odds_ratios = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            this_column = train.iloc[:,i]\n",
    "            table = np.zeros((2, 2))\n",
    "            temp = this_column[train_label==1]\n",
    "            table[0,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            table[1,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==1]\n",
    "            table[0,1] = temp[temp == 0].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            table[1,1] = temp[temp == 0].shape[0]\n",
    "            oddsratio, pvalue = stats.fisher_exact(table)\n",
    "            odds_ratios[i-1] = oddsratio\n",
    "            i+=1;\n",
    "        relevant_features = odds_ratios.sort_values(ascending=False)\n",
    "        new_train = train[relevant_features[0:nFeature+1].index] \n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "        \n",
    "    elif technique == \"DFS\":\n",
    "        i=1;\n",
    "        DFS_weights = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            this_column = train.iloc[:,i]\n",
    "            org_table = np.zeros((2, 1))# number of occurrence per each class\n",
    "            temp = this_column[train_label==1]\n",
    "            org_table[0,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            org_table[1,0] = temp[temp == 1].shape[0]\n",
    "            occurrence_of_word = train.iloc[:,i].sum()\n",
    "            numerator = org_table / occurrence_of_word # calculate numerator of DFS\n",
    "            # calculate denominator of DFS\n",
    "            n_negative = train_label.sum() # number of negative samples\n",
    "            n_positive = train_label.shape[0] - n_negative # number of positive samples\n",
    "            s1 = ((n_negative - org_table.item(0)) / n_negative ) + (( org_table.item(1)) / n_positive ) +1\n",
    "            s2 = ((n_positive - org_table.item(1)) / n_positive ) + (( org_table.item(0)) / n_negative ) +1\n",
    "            # calculate DFS\n",
    "            s = np.array([s1, s2])\n",
    "            s = np.transpose(numerator)/s\n",
    "            DFS_weights[i-1] = s.sum()\n",
    "            i+=1;\n",
    "        relevant_features = DFS_weights.sort_values(ascending=False)\n",
    "        new_train = train[relevant_features[0:nFeature+1].index]\n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label\n",
    "    \n",
    "    elif technique == \"Gini_Index&Odds_Ratio\":\n",
    "        i=0;\n",
    "        gini_indexes = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        odds_ratios = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            #Gini\n",
    "            gini_indexes[i] = gini(X[col])\n",
    "            #Odds ratio\n",
    "            this_column = train.iloc[:,i]\n",
    "            table = np.zeros((2, 2))\n",
    "            temp = this_column[train_label==1]\n",
    "            table[0,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            table[1,0] = temp[temp == 1].shape[0]\n",
    "            temp = this_column[train_label==1]\n",
    "            table[0,1] = temp[temp == 0].shape[0]\n",
    "            temp = this_column[train_label==0]\n",
    "            table[1,1] = temp[temp == 0].shape[0]\n",
    "            oddsratio, pvalue = stats.fisher_exact(table)\n",
    "            odds_ratios[i] = oddsratio\n",
    "            i+=1;\n",
    "        gini_odds = gini_indexes * odds_ratios\n",
    "        relevant_features = gini_odds.sort_values(ascending=False)\n",
    "        new_train = train[relevant_features[0:nFeature+1].index] \n",
    "        new_test = test[relevant_features[0: nFeature+1].index]\n",
    "        relevant_features = relevant_features[0:nFeature+1]\n",
    "        train_label =train_label.to_frame()\n",
    "        new_train = pd.concat([ train_label,new_train ],axis=1)#first column is label\n",
    "        test_label =test_label.to_frame()\n",
    "        new_test = pd.concat([ test_label,new_test],axis=1)#first column is label    \n",
    "        \n",
    "    elif technique == \"Gini_Indexes&PCA\":\n",
    "        #Gini\n",
    "        i=0;\n",
    "        gini_indexes = pd.Series(np.zeros([X.shape[1]]),index=X.columns )\n",
    "        for col in X.columns:\n",
    "            gini_indexes[i] = gini(X[col])\n",
    "            i+=1;\n",
    "        relevant_features = gini_indexes.sort_values(ascending=False)\n",
    "        new_train = train[relevant_features[0:(1*nFeature)+1].index]\n",
    "        new_test = test[relevant_features[0: (1*nFeature)+1].index]\n",
    "        relevant_features = relevant_features[0:(1*nFeature)+1]\n",
    "        #train_label =train_label.to_frame()\n",
    "        #test_label =test_label.to_frame()\n",
    "        #PCA\n",
    "        pca = PCA(n_components=nFeature)\n",
    "        pca.fit(new_train)\n",
    "        new_train = pca.transform(new_train)\n",
    "        new_test = pca.transform(new_test)\n",
    "        new_train = np.c_[ train_label,new_train ]#first column is label\n",
    "        new_test = np.c_[ test_label,new_test]#first column is label\n",
    "    \n",
    "    print(relevant_features)\n",
    "    return new_train, new_test ,relevant_features\n",
    "\n",
    "# classify data\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    DecisionTreeClassifier(),\n",
    "    MLPClassifier(alpha=1e-3,hidden_layer_sizes=(10),max_iter=100),\n",
    "    SVC(probability=True)]\n",
    "#techniques = [ 'Document_Frequency', 'Information_Gain', 'Gini_Index', \n",
    "#              'DFS','Odds_Ratio','Correlation','Gini_Index&Odds_Ratio',\n",
    "#              'Gini_Indexes&PCA','Correlation&Information_Gain']\n",
    "techniques = [ 'Correlation&DF', 'Correlation&DFS', 'Odds_Ratio&DF', \n",
    "              'Odds_Ratio&DFS','Odds_Ratio&Information_Gain','Correlation&Gini']\n",
    "\n",
    "for Technique in techniques:\n",
    "    #Number Of selected Features\n",
    "    number_of_feature = 100\n",
    "    #Feature Selection\n",
    "    new_Train,new_Test,Relevant_Features =  feature_selection_technique(train_data, test_data, Technique, number_of_feature)\n",
    "    # set new train and test\n",
    "    if Technique == \"Information_Gain\" or Technique == \"Gini_Indexes&PCA\":\n",
    "        X_train = new_Train[0::, 1::] # second column to last column\n",
    "        y_train = new_Train[0::, 0] # just first column is lable\n",
    "        X_test = new_Test[0::, 1::]\n",
    "        y_test = new_Test[0::, 0]\n",
    "    else:\n",
    "        X_train = new_Train.iloc[:,1:] # second column to last column\n",
    "        y_train = new_Train.iloc[:,0] # just first column is lable\n",
    "        X_test = new_Test.iloc[:,1:]\n",
    "        y_test = new_Test.iloc[:,0]\n",
    "    \n",
    "    # run classifiers for this technique\n",
    "    for clf in classifiers:\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "    \n",
    "        # Calculate Accuracy Rate by using accuracy_score()\n",
    "        print(Technique+'---------------------------------------')\n",
    "        print (clf.__class__.__name__ + \" test Accuracy Rate is: %f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "        print (clf.__class__.__name__ + \" F1_micro is: %f\" % f1_score(y_test, y_pred, average='micro'))\n",
    "        print (clf.__class__.__name__ + \" F1_macro is: %f\" % f1_score(y_test, y_pred, average='macro'))\n",
    "        f1_sc = f1_score(y_test, y_pred, average=None)\n",
    "        print('f1_score is: %f' % f1_sc.mean())\n",
    "        print(\"RMSE= \" ,np.sqrt(mean_squared_error(y_test,y_pred)) )\n",
    "\n",
    "        scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "        print(\"validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
