{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.neighbors import RadiusNeighborsClassifier\n",
    "from sklearn.neighbors.kde import KernelDensity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "# Load data\n",
    "data = pd.read_csv('bow&dic/bow_train_over15.csv')\n",
    "DF_file = pd.ExcelFile('bow&dic/df_Dic_org_over15_t.xlsx')\n",
    "dfreq = DF_file.parse('Sheet1')\n",
    "data.columns = dfreq.columns\n",
    "data = data.drop(\"['positive'\", axis=1)\n",
    "#data = data.drop(columns=[ '0.1'])# delete positive column\n",
    "#data = data[:100] \n",
    "\n",
    "\n",
    "row_count = data.shape[0]\n",
    "split_point = int(row_count*4/5)\n",
    "train_data, test_data = data[:split_point], data[split_point:]\n",
    "\n",
    "classifiers = [\n",
    "    GaussianNB(),\n",
    "    KNeighborsClassifier(n_neighbors=3),\n",
    "    NearestCentroid(), \n",
    "    RadiusNeighborsClassifier(radius=50.0),\n",
    "    #LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "#kde = KernelDensity().fit(X_train)\n",
    "#kde.score_samples(X_train) \n",
    "X_train = train_data.iloc[:,1:] # second column to last column\n",
    "y_train = train_data.iloc[:,0] # just first column is lable\n",
    "X_test = test_data.iloc[:,1:]\n",
    "y_test = test_data.iloc[:,0]\n",
    "    \n",
    "# run classifiers for this technique\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    # Calculate Accuracy Rate by using accuracy_score()\n",
    "    print('---------------------------------------')\n",
    "    print (clf.__class__.__name__ + \" test Accuracy Rate is: %f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "    print (clf.__class__.__name__ + \" F1_micro is: %f\" % f1_score(y_test, y_pred, average='micro'))\n",
    "    print (clf.__class__.__name__ + \" F1_macro is: %f\" % f1_score(y_test, y_pred, average='macro'))\n",
    "    f1_sc = f1_score(y_test, y_pred)\n",
    "    #print('f1_score is: %f' % f1_sc.mean())\n",
    "    print('f1_score is: %f' % f1_sc)\n",
    "    print(\"RMSE= \" ,np.sqrt(mean_squared_error(y_test,y_pred)) )\n",
    "\n",
    "    scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "    print(\"validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "'''    \n",
    "# linear model LogisticRegression degree =2\n",
    "polynomial_features= PolynomialFeatures(degree=2)\n",
    "x_poly = polynomial_features.fit_transform(X_train)\n",
    "x_poly_test = polynomial_features.fit_transform(X_test)\n",
    "model = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "model.fit(x_poly, y_train)\n",
    "y_poly_pred = model.predict(x_poly_test)\n",
    "# Calculate Accuracy Rate by using accuracy_score()\n",
    "print('---------------------------------------')\n",
    "print ('LogisticRegression_degree = 2'+ \" test Accuracy Rate is: %f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "print ('LogisticRegression_degree = 2' + \" F1_micro is: %f\" % f1_score(y_test, y_pred, average='micro'))\n",
    "print ('LogisticRegression_degree = 2' + \" F1_macro is: %f\" % f1_score(y_test, y_pred, average='macro'))\n",
    "f1_sc = f1_score(y_test, y_pred, average=None)\n",
    "print('f1_score is: %f' % f1_sc.mean())\n",
    "print(\"RMSE= \" ,np.sqrt(mean_squared_error(y_test,y_pred)) )\n",
    "\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=10)\n",
    "print(\"validation Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
